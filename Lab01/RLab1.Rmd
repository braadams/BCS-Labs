---
title: "R Coding Lab Part 1"
subtitle: "STAT-4/510: Basic Consulting SKills "
author: Braxton Adams, Cyrus Cravens, Jonathan Adiri, Sang Xing
output: 
  rmdformats::downcute:
    highlight: tango
    code_folding: show  
    default_style: "dark"
    toc_depth: 3
df_print: kable   
---

```{r setup, include=FALSE}
options(width=120)
knitr::opts_chunk$set(echo = TRUE)
```

```{css, echo=FALSE}
.title, .subtitle, .authors{
  text-align: center;
}

.glyphicon{
  display: none;
}

h1.subtitle {
    font-size: 1rem;
    font-weight: 100;
}

[data-theme='dark']
.page-content .code-mask, .page-content pre{
  background-color: #4d619657;
}

.page-content code{
  background: #4d619657;
  color: #fff;
}

[data-theme='light']
.page-content .code-mask, .page-content pre{
  background-color: #292c34;
}

.page-content code{
  background: #292c34;
  color: #fff;
}

```

**Complete the following lab as a group. This document should exist in your GitHub repo while you're working on it. Your code should be heavily commented so someone reading your code can follow along easily. See the first code snippet below for an example of commented code.**

**Here's the catch: For any given problem, the person writing the code should not be the person commenting that code, and every person must both code AND comment at least one problem in this lab (you decide how to split the work). This will involve lots of pushing and pulling through Git, and you may have to resolve conflicts if you're not careful! Refer to last Thursday's class notes for details on conflict resolution.**

**Use only tools covered on Tuesday's lecture (including those discussed on the lecture recording)**.

# Playing With Cherry Blossom Race Data
## 1
First load the data, which is saved as a .RData file called `CBdata.1_10.RData`. This is the first ten years' worth of Cherry Blossom Race data. Pull out the data associated with 1976 and store it as a data frame called `dat.76`. Remove the column `Pis/Tis`. 


```{r import_data}
load("CBdata.1_10.RData") #Loading the cherry blossom data. (this is an example of a properly commented line of code)

#Now write code to remove the specified column
dat.76 <- CBdata.1_10[[4]] # Copy index 4 from CBdata (1976)
dat.76 <- dat.76[-6] # Remove column 6 (Pis/Tis)
head(dat.76)
```

## 2
The function `summary()` is useful for learning basic facts about vectors, data frames, and many other R objects. Use this function to find the mean and median recorded ages in 1976. 

```{r summary}
summary(dat.76) # display summary
# Age mean  : 32.09
# Age median: 32.00
```
**ANS:** The age Median is 32.00 and the age Mean is 32.09 

## 3
You might have noticed that a number of age values are missing (i.e. `NA`). Your next goal is to write a loop that removes observations that don't have age data.  
Hints:  
- The `is.na()` function may be useful. Use the `?is.na` command to pull up documentation on this function. It might be helpful to play around with a toy example like `c(1,2,NA,3)` to make sure you understand this new function!  
- Depending on how you write your code, you may need to negate a logical vector using `!`. Ex: `!c(TRUE, TRUE, FALSE)` is identical to `c(FALSE, FALSE, TRUE)`.

```{r filter_missing_age_loop}
dat.76.clean <- NULL       #Creating new empty variable to store the cleaned data
for(x in 1:nrow(dat.76)) { #Creating a loop that will go from one to the number of rows (942)
  if(!is.na(dat.76[x, "Age"])) { #checking if the current row is not an NA
    dat.76.clean <- rbind(dat.76.clean, dat.76[x,]) #Appending the new variable with the non NA row.
  }
}
```

## 4
Now use vectorization and the `is.na()` function to accomplish the same thing as the loop above.  
How to check your work: If your loop produced a data frame called "dat.76.clean" and the vectorization approach produced a data frame called `dat.76.clean2`, the `identical(dat.76.clean,dat.76.clean2)` should return `TRUE`.

```{r filter_missing_age_vectorization}
dat.76.clean2 <- dat.76[-which(is.na(dat.76$Age)),] # Find the indices of the Age entries that are NAs and drop them from the data frame

identical(dat.76.clean, dat.76.clean2) 
```

## 5
Filtering out missing age data could be useful when dealing with other years. With this in mind, turn your filter loop or vectorization approach into a function. You should be able to use the function like this: `dat.76.clean <- filter.func(dat.76)`.  
When you have a function written, run it on the 1976 data and use identical() to verify that your function and the first loop you wrote are doing the same thing.

```{r filter_func}
filter.func <- function(dat){  
  dat[-which(is.na(dat$Age)),] # If the observation has a NA Age, drop it from the dataframe
}

dat.76.clean3 <- filter.func(dat.76) # Run function on our dataframe

identical(dat.76.clean,dat.76.clean3)
```

## 6
Next, write a loop that combines all of the data from `CBdata.1_10` into one cleaned data frame. Make sure your final data frame has neither the `Pis/Tis` column nor `NA` Age values.  
Use the `identical()` function to verify that the 1976 data in this larger cleaned data set is the same as the cleaned version of `dat.76`. 

```{r combine_dat}
CBdata.1_10df <- NULL # Create name for the combined dataframe 
for (i in CBdata.1_10){ 
 CBdata.1_10df <- rbind(CBdata.1_10df,i) # Bind each dataframe in the list by rows
}

CBdata.1_10_clean <- CBdata.1_10df[-6] # Drop Pis/Tis column
CBdata.1_10_clean <- filter.func(CBdata.1_10_clean) # Drop NA Age observations

dat.76.clean4 <- CBdata.1_10_clean[CBdata.1_10_clean$Year==1976,] # filter only 1976 data to verify it matches the previous chunks

rownames(dat.76.clean) <- NULL # Drop row names (otherwise the indicies won't match!)
rownames(dat.76.clean4) <- NULL

identical(dat.76.clean4,dat.76.clean)
```

## 7
Now that you have the combined data set for these 10 years, let's do some basic exploration:  
a) How does the average of the recorded ages in 1976 compare to that same average over the entire `CBdata.1_10` data set?  
b) Recall that the `CBdata.1_10` contains the first ten year's worth of cherry blossom race data. How does the average participant age over the first five years compare to the average age over years 6-10?

```{r}
mean(dat.76.clean$Age)
mean(CBdata.1_10_clean$Age)

mean(CBdata.1_10_clean$Year])
```


# Playing with the indoor positioning system data

The `IPS_sampledata` data set contains a fraction of the indoor positioning system data for 15 randomly sampled locations.This data set is loaded into memory using the chunk of R code below, complete the following exercises. 

```{r eval=T, echo=T}
# loads data set IPS_sampledata
load("IPS_portion.RData")
```

## Variable dictionary

- `time`: timestamp in milliseconds since midnight 01/01/1970 UTC

- `scanMac`: MAC address of the scanning device (this is a handheld device)

- `posX`, `posY` and `posZ`: the (x, y, z) physical coordinate of the scanning device

- `orientation`: degree orientation of the user carrying the scanning device in degrees

- `mac`: MAC address of an access point

- `signal`: signal strength in dBm (Decibel-milliwatts)

- `channel`: the channel frequency

- `type`: type of device (access point = 3, device in adhoc mode = 1)

Let's clean up the data a bit!

## 1
First apply the `summary` function to the `IPS_data` to get a sense of what is available in that data frame. 

```{r}
summary(IPS_sampledata) # Summary of IPS data frame
```

## 2
Identify variables that need any `class` conversion. Attempting to avoid code-replication as much as possible, convert these variables into the correct class type.

```{r}
colNameList1 <- c("time", "posX", "posY", "posZ", "orientation", "signal") # List of numeric variables
IPS_sampledata[colNameList1] <- lapply(IPS_sampledata[colNameList1], as.numeric) # Convert these variables to numeric
colNameList2 <- c("mac", "channel", "scanMac") # List of factor variables
IPS_sampledata[colNameList2] <- lapply(IPS_sampledata[colNameList2], as.factor) # Convert these variables to factors
```

## 3
Because we only want data relative to access points, remove observations that correspond to any other type of device.

```{r}
IPS_sampledata <- IPS_sampledata[IPS_sampledata$type=="3",] # Filter only access point observations
```

## 4
Assess if there are any variables that provide redundant or no information. If so, remove them from the data frame.

```{r}
length(unique(IPS_sampledata$scanMac)) # Are there more than one unique values for scanMac and posZ?
length(unique(IPS_sampledata$posZ))
IPS_sampledata$scanMac <- NULL # Set these two variables to NULL
IPS_sampledata$posZ <- NULL
IPS_sampledata <- IPS_sampledata[!sapply(IPS_sampledata, is.null)] # If a variable is NULL, remove them
```

## 5
Note that the `time` variable is in milliseconds.  Transform it into seconds and then convert its class into a time format using the function `as.POSIXct`.

```{r}
IPS_sampledata$time <- IPS_sampledata$time/1000 # Convert time from milliseconds to seconds
IPS_sampledata$time <- as.POSIXct(IPS_sampledata$time, tz="UTC", origin = "1970-01-01") # Convert to time format
```

## Examining the data more closely

## 1
Create the function `tally_mac` whose only input is the MAC address of an access point, and returns the number of observations found in the data set for it.

```{r}
tally_mac <- function(mac_obs){
  print(table(IPS_sampledata$mac==mac_obs)[["TRUE"]]) # Count the number of entries that match mac_obs and return the value
}

tally_mac("00:0f:a3:39:dd:cd")
```

## 2
Use the function `unique` to identify the unique levels for `mac` found in the data set.

```{r}
print(length(unique(IPS_sampledata$mac))) # 
```

## 3
Using an approach learned in class together with `tally_mac`, tally the  number of observations for all access points in the data. While the researchers did their best to clean their data, some noise was introduced by access points on other floors.  Based on the number of counts, identify and remove likely suspects for access points read by mistake.

```{r}
sort(summary(IPS_sampledata$mac), decreasing = TRUE,) # Tally the IPS_sample mac addresses and sort in decreasing order
IPS_sampledata <- IPS_sampledata[IPS_sampledata$mac %in% names(sort(summary(IPS_sampledata$mac), decreasing = TRUE,))[1:7],] # Using the above summary, only include mac addresses that are in the 7 largest counts
```

## 4
The orientation of the hand-held device considered was supposed to be exactly set to the 8 angles from 0-360 in increments of 45 degrees (360 is equivalent to 0). However, in practice the measured orientations were close to the 8 expected but had some error, so we'll need to group them.  Develop and apply a function to recode the orientation values as one of 0, 45, 90, 135, 180, 225, 270, 315. Call the recoded orientation variable `rec_orient`.

```{r}
rec_orient <- function(orientation) {
  angles = seq(from=0, to=360, by=45) # Generate a list of the orientation values
  q = sapply(orientation, function(index) which.min(abs(index-angles))) # Given a list of orientations, return the orientation angle that is closest for each item
  # if (orientation >= 0){
  #   q = sapply(orientation, function(index) which.min(abs(index-angles)))
  # } else{
  #   q = sapply(orientation, function(index) 10-which.min(abs(angles+index)))
  # }
  directions_index <- c(1:8, 1)[q] # Convert q to an item from 1-8, where 1 is E, 2 is NE, etc
  directions = c("E→", "NE↗", "N↑", "NW↖", "W←", "SW↙", "S↓", "SE↘") # "pretty print" versions of the orientation list
  directions[directions_index] # Convert directions_input to the "pretty print" versions
  # angles = paste(angles, directions, sep = '=') concatenate angles with directions
}

IPS_sampledata$orientation <- rec_orient(IPS_sampledata$orientation) # Apply function from above to orientation data
head(IPS_sampledata) # Display the first six entries
```

## 5
Create the function `signal_summary` that takes as inputs a location (`posX`, `posY`, `posZ`), an orientation (`rec_orient`) and an access point id (`mac`).  The function must identify and subset the rows in `IPS_sampledata` corresponding to this unique combination, then it must calculate and return the mean and standard deviation for the corresponding signal strengths. 

```{r}
signal_summary <- function (dat, posX, posY, orientation, mac) {
  signal_stat = dat[dat$posX==posX &
                               dat$posY==posY &
                               dat$orientation==orientation &
                               dat$mac==mac,]
  list(
    mean = mean(signal_stat$signal),
    sd = sd(signal_stat$signal)
  )
}

head(signal_summary(IPS_sampledata, 1, 9, "E→",	"00:14:bf:b1:97:8a"))
```

## 6
Create a list where each entry corresponds to a named list including unique combination of a location, an orientation, and an access point.  Use this list in combination with `lapply` and `signal_summary` to generate a summary of signals for each unique combination. `Hint`: you may want to create a new variable with a unique identifier that combines location, `rec_orient` and `mac` to make your life simpler.  One way to go about this is using the `paste` function (see `?paste` for help on its use) with these variables in a row-by-row fashion.

```{r}
IPS_sampledata$uniqueID <- paste(IPS_sampledata$posX, IPS_sampledata$posY, IPS_sampledata$orientation,  IPS_sampledata$mac, sep="|")

filter_data <- function(id) {
  dat <- IPS_sampledata[IPS_sampledata$uniqueID == id,]
  entry.1 <- dat[1,]
  signal_summary(dat, entry.1$posX, entry.1$posY, entry.1$orientation, entry.1$mac)
}

IDs <- unique(IPS_sampledata$uniqueID)

full.summary <- lapply(IDs, filter_data)
names(full.summary) <- IDs
head(full.summary)
```


